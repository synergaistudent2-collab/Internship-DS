{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Lifecycle Basics\n",
    "\n",
    "## 1. README\n",
    "\n",
    "### **Objective**\n",
    "This notebook provides a basic, end-to-end walkthrough of the data science lifecycle using the classic Titanic survival dataset. It covers problem definition, data collection, cleaning, exploratory data analysis (EDA), feature engineering, modeling, evaluation, a toy deployment example, and an introduction to monitoring. The goal is to provide a simple, runnable example for an intern or beginner to understand the flow of a typical data science project.\n",
    "\n",
    "### **Setup Instructions**\n",
    "1.  **Create a virtual environment:** It's best practice to isolate your project's dependencies. \n",
    "    * On macOS/Linux:\n",
    "        ```bash\n",
    "        python3 -m venv .venv\n",
    "        source .venv/bin/activate\n",
    "        ```\n",
    "    * On Windows:\n",
    "        ```bash\n",
    "        python -m venv .venv\n",
    "        .venv\\Scripts\\activate\n",
    "        ```\n",
    "2.  **Install dependencies:** Ensure all required libraries are installed. The `-U` flag updates existing packages.\n",
    "    ```bash\n",
    "    pip install -U pip\n",
    "    pip install pandas numpy matplotlib seaborn scikit-learn joblib jupyter\n",
    "    ```\n",
    "3.  **Run the notebook:** Start the Jupyter Notebook server in the same directory.\n",
    "    ```bash\n",
    "    jupyter notebook\n",
    "    ```\n",
    "    Then, open `ds_lifecycle_basics.ipynb` in your browser.\n",
    "\n",
    "---\n",
    "\n",
    "# Data Science Lifecycle Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Phase 1 – Problem Definition\n",
    "\n",
    "**Business Problem:** We want to predict which passengers survived the sinking of the Titanic. This is a classic **classification problem**. Understanding the factors that influenced survival can provide valuable insights, such as what characteristics (e.g., age, gender, class) were most important in determining a person's fate. This type of analysis could be used for historical research or as a learning exercise in machine learning.\n",
    "\n",
    "**Target Variable:** The `Survived` column. It is a binary variable where `0` = did not survive and `1` = survived.\n",
    "\n",
    "**Success Criteria:** Since this is a simple introductory model, we'll aim for a reasonable accuracy score. Our primary metrics will be **accuracy, precision, and recall**. We will use a **confusion matrix** and an **ROC curve** to better understand the model's performance beyond a single number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phase 2 – Data Collection\n",
    "\n",
    "We will load the data directly from a public URL, ensuring the notebook is self-contained and reproducible. The dataset is sourced from the `datasciencedojo` GitHub repository, which is a common source for introductory datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Set a random seed for reproducibility across the notebook\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset URL\n",
    "data_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(data_url)\n",
    "    print(\"Data loaded successfully from URL.\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "    \n",
    "if df is not None:\n",
    "    # Display basic information about the dataset\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\nColumn Information:\\n\")\n",
    "    df.info()\n",
    "    print(\"\\nFirst 5 rows:\\n\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 3 – Data Cleaning and EDA\n",
    "\n",
    "This phase involves handling missing data, converting data types, and exploring relationships within the data through visualizations. We'll identify missing values and decide on a strategy to handle them. For EDA, we'll look at the distribution of key features and their relationship with the target variable, `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Strategy for missing values:\n",
    "# 'Age' has a significant number of missing values. We will impute them with the median to avoid skewing the distribution with the mean.\n",
    "# 'Cabin' has too many missing values (~77%) to be useful, so we will drop this column.\n",
    "# 'Embarked' has only 2 missing values. We will fill them with the most frequent value (mode).\n",
    "\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic EDA\n",
    "# Univariate Analysis: Distribution of 'Age'\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Age'], kde=True, bins=30)\n",
    "plt.title('Distribution of Passenger Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Bivariate Analysis: Survival Rate by Sex\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Sex', y='Survived', data=df)\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()\n",
    "print(\"\\nInsight: Females had a significantly higher survival rate than males.\\n\")\n",
    "\n",
    "# Bivariate Analysis: Survival Rate by Passenger Class (P-class)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Pclass', y='Survived', data=df)\n",
    "plt.title('Survival Rate by Passenger Class')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()\n",
    "print(\"\\nInsight: Passengers in higher classes (1st class) had a much higher survival rate.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase 4 – Feature Engineering\n",
    "\n",
    "Feature engineering is the process of using domain knowledge to create new features that are more informative and can improve model performance. We will create two new features: `FamilySize` and `IsAlone`. We'll also extract a `Title` from the `Name` column to capture social status, which is often a strong predictor of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FamilySize feature\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Create IsAlone feature\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Extract Title from Name\n",
    "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Replace rare titles with a single 'Rare' category\n",
    "rare_titles = df['Title'].value_counts()[df['Title'].value_counts() < 10].index\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "print(\"Top 5 most common titles after cleaning:\\n\", df['Title'].value_counts().head())\n",
    "\n",
    "# Drop original features that are no longer needed\n",
    "df.drop(['Name', 'Ticket', 'PassengerId', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Define which features are numerical and which are categorical\n",
    "numerical_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'IsAlone']\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "# StandardScaler is used to normalize numerical features. This is important for many machine learning algorithms to perform optimally.\n",
    "# OneHotEncoder converts categorical features into a numerical format that the model can understand.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"\\nFinal feature matrix shape (after preprocessing setup):\", (preprocessor.fit_transform(X).shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase 5 – Modeling\n",
    "\n",
    "We will split the data into training and testing sets to evaluate our model on unseen data. Then, we will train a simple Logistic Regression model. Logistic Regression is a good baseline model for classification tasks because it's fast, interpretable, and effective for many problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "\n",
    "# Create the modeling pipeline\n",
    "# The Pipeline object combines the preprocessing steps and the model into a single estimator.\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model on the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase 6 – Evaluation\n",
    "\n",
    "After training the model, we need to evaluate its performance on the test set. We will use several metrics to get a comprehensive view of how well the model performs. We'll also visualize the confusion matrix and the ROC curve to better understand its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Did Not Survive', 'Survived'], yticklabels=['Did Not Survive', 'Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: The model's accuracy is decent, but precision and recall show trade-offs. The ROC curve indicates the model has good discriminative power.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phase 7 – Deployment (Toy Example)\n",
    "\n",
    "After a model is trained and evaluated, it's ready to be used in production. We can save the entire pipeline (including preprocessing steps) to a file using `joblib`. This ensures that when the model is reloaded, it will apply the exact same transformations to new data as it did during training, preventing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained pipeline to a file\n",
    "model_filename = 'titanic_survival_model.joblib'\n",
    "joblib.dump(model_pipeline, model_filename)\n",
    "\n",
    "print(f\"Model and preprocessor saved to {model_filename}\")\n",
    "\n",
    "# --- Toy Deployment Simulation --- #\n",
    "\n",
    "# Load the saved model in a new environment\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "print(\"\\nModel loaded successfully.\")\n",
    "\n",
    "# Create a small sample of new data (simulating a live prediction request)\n",
    "new_data = pd.DataFrame([\n",
    "    # Sample 1: A female from 1st class (likely to survive)\n",
    "    {'Pclass': 1, 'Sex': 'female', 'Age': 28, 'SibSp': 0, 'Parch': 0, 'Fare': 70.0, 'Embarked': 'S', 'Name': 'Mrs. Test', 'IsAlone': 1, 'FamilySize': 1, 'Title': 'Mrs'},\n",
    "    # Sample 2: A male from 3rd class (less likely to survive)\n",
    "    {'Pclass': 3, 'Sex': 'male', 'Age': 45, 'SibSp': 1, 'Parch': 2, 'Fare': 25.0, 'Embarked': 'C', 'Name': 'Mr. Test', 'IsAlone': 0, 'FamilySize': 4, 'Title': 'Mr'}\n",
    "])\n",
    "\n",
    "# Use the loaded model to make a prediction on the new data\n",
    "predictions = loaded_model.predict(new_data)\n",
    "\n",
    "print(\"\\nPredictions on new data:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    status = 'Survived' if pred == 1 else 'Did Not Survive'\n",
    "    print(f\"Sample {i+1}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Phase 8 – Monitoring (Intro Level)\n",
    "\n",
    "After deployment, it's crucial to monitor the model's performance in the real world. Over time, the distribution of incoming data can change (**data drift**), which can cause the model's performance to degrade. We'll simulate a simple check for data drift by comparing the mean of a key feature from our training data to a new, hypothetical batch of incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a new, small batch of incoming data\n",
    "np.random.seed(1)\n",
    "incoming_data_sample = df.sample(n=50, replace=False, random_state=1)\n",
    "\n",
    "print(\"Simulating Monitoring Checks:\")\n",
    "print(f\"Model Version: v1.0\")\n",
    "print(f\"Data Timestamp: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. Data Schema Check (simplified)\n",
    "if sorted(list(incoming_data_sample.columns)) == sorted(list(df.columns)):\n",
    "    print(\"\\nSchema Check: PASS. Incoming data columns match training data.\")\n",
    "else:\n",
    "    print(\"\\nSchema Check: FAIL. Column mismatch detected.\")\n",
    "\n",
    "# 2. Simple Data Drift Check (comparing mean 'Age')\n",
    "train_age_mean = X_train['Age'].mean()\n",
    "incoming_age_mean = incoming_data_sample['Age'].mean()\n",
    "\n",
    "mean_diff = abs(train_age_mean - incoming_age_mean)\n",
    "tolerance = 2.0  # Set a simple threshold for drift detection\n",
    "\n",
    "print(f\"\\nTraining 'Age' Mean: {train_age_mean:.2f}\")\n",
    "print(f\"Incoming 'Age' Mean: {incoming_age_mean:.2f}\")\n",
    "\n",
    "if mean_diff > tolerance:\n",
    "    print(f\"\\nData Drift Alert: The mean 'Age' has shifted by more than {tolerance:.2f}.\")\n",
    "else:\n",
    "    print(f\"\\nData Drift Check: PASS. Mean 'Age' is within tolerance.\")\n",
    "\n",
    "# In a real-world scenario, you would log these metrics and send alerts automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "\n",
    "## Conclusion and Next Steps\n",
    "\n",
    "This notebook has walked through the complete data science lifecycle, from understanding a problem to a basic simulation of model monitoring. We successfully trained a simple Logistic Regression model that achieved a reasonable performance on the Titanic dataset.\n",
    "\n",
    "**Key Findings:**\n",
    "* Gender and passenger class were the most influential factors in survival.\n",
    "* The model's performance, while good, could be improved with more advanced feature engineering and a more complex model.\n",
    "\n",
    "**Known Limitations:**\n",
    "* The model is a simple linear classifier. More complex models like Gradient Boosting or a Random Forest might yield better results.\n",
    "* The dataset is small and historical. Real-world data is often messier and larger.\n",
    "\n",
    "**Next Steps:**\n",
    "* Experiment with different models (e.g., `RandomForestClassifier`).\n",
    "* Use more sophisticated methods for handling missing values and feature engineering.\n",
    "* Perform **hyperparameter tuning** to optimize the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}