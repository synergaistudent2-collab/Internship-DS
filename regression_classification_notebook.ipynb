{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Classification with Linear Models, Decision Trees, and Cross-Validation\n",
    "\n",
    "**Objective:** Demonstrate end-to-end ML workflows for regression and classification, including regularization, hyperparameter tuning, cross-validation, and overfitting analysis.\n",
    "\n",
    "**Author:** ML Intern Tutorial  \n",
    "**Date:** 2025  \n",
    "**Estimated Time:** 6-8 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Quickstart\n",
    "\n",
    "Before running this notebook, ensure you have the required packages installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy==1.24.3 pandas==2.0.3 scikit-learn==1.3.0 matplotlib==3.7.2 seaborn==0.12.2 jupyter==1.0.0\n",
    "```\n",
    "\n",
    "Then run all cells from top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction and Goals](#introduction)\n",
    "2. [Setup and Imports](#setup)\n",
    "3. [Data Loading and EDA](#eda)\n",
    "4. [Train/Validation/Test Split](#split)\n",
    "5. [Data Preprocessing](#preprocessing)\n",
    "6. [Baseline Models](#baseline)\n",
    "7. [Regression: California Housing](#regression)\n",
    "8. [Classification: Breast Cancer](#classification)\n",
    "9. [Conclusions and Next Steps](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Goals <a id='introduction'></a>\n",
    "\n",
    "### Goals of This Notebook\n",
    "\n",
    "This notebook demonstrates comprehensive machine learning workflows covering:\n",
    "\n",
    "1. **Regression Task:** Predict California housing prices using Linear Regression, Ridge, Lasso, and Decision Trees\n",
    "2. **Classification Task:** Diagnose breast cancer (malignant vs. benign) using Logistic Regression and Decision Trees\n",
    "3. **Key Concepts:**\n",
    "   - Regularization techniques (L1, L2) to prevent overfitting\n",
    "   - Cross-validation for robust model evaluation\n",
    "   - Hyperparameter tuning using GridSearchCV\n",
    "   - Learning curves and validation curves for bias-variance analysis\n",
    "   - Feature importance interpretation\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- How to build end-to-end ML pipelines\n",
    "- When and why to use regularization\n",
    "- How to detect and mitigate overfitting/underfitting\n",
    "- Best practices for model selection and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn: datasets\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "\n",
    "# Scikit-learn: preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scikit-learn: models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "\n",
    "# Scikit-learn: model selection and evaluation\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    KFold, \n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    learning_curve,\n",
    "    validation_curve\n",
    ")\n",
    "\n",
    "# Scikit-learn: metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"Random state set to: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and EDA <a id='eda'></a>\n",
    "\n",
    "We'll load two datasets:\n",
    "1. **California Housing** - Regression task (predict median house value)\n",
    "2. **Breast Cancer Wisconsin** - Classification task (diagnose tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 California Housing Dataset (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California Housing dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df_housing = housing.frame\n",
    "\n",
    "print(\"California Housing Dataset\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df_housing.shape}\")\n",
    "print(f\"\\nFeatures: {list(housing.feature_names)}\")\n",
    "print(f\"\\nTarget: {housing.target_names[0]}\")\n",
    "print(f\"\\nTarget description: Median house value (in $100,000s)\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_housing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df_housing.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df_housing.isnull().sum().sum()}\")\n",
    "if df_housing.isnull().sum().sum() == 0:\n",
    "    print(\"âœ“ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution and feature correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Target distribution\n",
    "axes[0].hist(df_housing['MedHouseVal'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Median House Value ($100k)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Target Variable', fontsize=13, fontweight='bold')\n",
    "axes[0].axvline(df_housing['MedHouseVal'].mean(), color='red', \n",
    "                linestyle='--', label=f\"Mean: {df_housing['MedHouseVal'].mean():.2f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_matrix = df_housing.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, ax=axes[1], cbar_kws={'label': 'Correlation'})\n",
    "axes[1].set_title('Feature Correlation Matrix', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop correlations with target (MedHouseVal):\")\n",
    "target_corr = corr_matrix['MedHouseVal'].sort_values(ascending=False)\n",
    "print(target_corr[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Breast Cancer Dataset (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Breast Cancer dataset\n",
    "cancer = load_breast_cancer(as_frame=True)\n",
    "df_cancer = cancer.frame\n",
    "\n",
    "print(\"Breast Cancer Wisconsin Dataset\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df_cancer.shape}\")\n",
    "print(f\"\\nNumber of features: {len(cancer.feature_names)}\")\n",
    "print(f\"\\nTarget classes: {cancer.target_names}\")\n",
    "print(f\"  0 = malignant (cancerous)\")\n",
    "print(f\"  1 = benign (non-cancerous)\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df_cancer['target'].value_counts().sort_index())\n",
    "print(f\"\\nClass balance: {df_cancer['target'].value_counts(normalize=True).sort_index()}\")\n",
    "print(\"\\nFirst 5 rows (showing first 10 columns):\")\n",
    "display(df_cancer.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary (first 10 features for brevity)\n",
    "print(\"Statistical Summary (first 10 features):\")\n",
    "display(df_cancer.iloc[:, :10].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df_cancer.isnull().sum().sum()}\")\n",
    "if df_cancer.isnull().sum().sum() == 0:\n",
    "    print(\"âœ“ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution and top feature correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Class distribution\n",
    "class_counts = df_cancer['target'].value_counts().sort_index()\n",
    "axes[0].bar(['Malignant', 'Benign'], class_counts.values, \n",
    "            color=['#e74c3c', '#2ecc71'], edgecolor='black', alpha=0.7)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].set_title('Class Distribution', fontsize=13, fontweight='bold')\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Top 10 features correlation with target\n",
    "# Select only mean features for cleaner visualization\n",
    "mean_features = [col for col in df_cancer.columns if 'mean' in col]\n",
    "mean_features.append('target')\n",
    "corr_with_target = df_cancer[mean_features].corr()['target'].drop('target').sort_values()\n",
    "top_corr = pd.concat([corr_with_target.head(5), corr_with_target.tail(5)])\n",
    "colors = ['red' if x < 0 else 'green' for x in top_corr.values]\n",
    "top_corr.plot(kind='barh', ax=axes[1], color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Correlation with Target', fontsize=11)\n",
    "axes[1].set_title('Top 10 Feature Correlations with Target', fontsize=13, fontweight='bold')\n",
    "axes[1].axvline(0, color='black', linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Validation/Test Split <a id='split'></a>\n",
    "\n",
    "### Split Strategy\n",
    "\n",
    "We'll use a **70/15/15 split**:\n",
    "- **70% Training:** For model training\n",
    "- **15% Validation:** For hyperparameter tuning and model selection\n",
    "- **15% Test:** For final unbiased performance evaluation\n",
    "\n",
    "**Rationale:** \n",
    "- 70% training provides sufficient data for learning patterns\n",
    "- 15% validation is enough for reliable hyperparameter evaluation\n",
    "- 15% test reserved for final assessment (touched only once)\n",
    "- Alternative 60/20/20 works well for smaller datasets\n",
    "\n",
    "**Important:** We stratify the classification split to maintain class balance across sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split California Housing (Regression)\n",
    "X_housing = df_housing.drop('MedHouseVal', axis=1)\n",
    "y_housing = df_housing['MedHouseVal']\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train_h, X_temp_h, y_train_h, y_temp_h = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.30, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Second split: 15% validation, 15% test (from the 30% temp)\n",
    "X_val_h, X_test_h, y_val_h, y_test_h = train_test_split(\n",
    "    X_temp_h, y_temp_h, test_size=0.50, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"California Housing Split:\")\n",
    "print(f\"  Training:   {X_train_h.shape[0]} samples ({X_train_h.shape[0]/len(X_housing)*100:.1f}%)\")\n",
    "print(f\"  Validation: {X_val_h.shape[0]} samples ({X_val_h.shape[0]/len(X_housing)*100:.1f}%)\")\n",
    "print(f\"  Test:       {X_test_h.shape[0]} samples ({X_test_h.shape[0]/len(X_housing)*100:.1f}%)\")\n",
    "print(f\"  Total:      {len(X_housing)} samples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Breast Cancer (Classification) - with stratification\n",
    "X_cancer = df_cancer.drop('target', axis=1)\n",
    "y_cancer = df_cancer['target']\n",
    "\n",
    "# First split: 70% train, 30% temp (stratified)\n",
    "X_train_c, X_temp_c, y_train_c, y_temp_c = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.30, random_state=RANDOM_STATE, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# Second split: 15% validation, 15% test (stratified from the 30% temp)\n",
    "X_val_c, X_test_c, y_val_c, y_test_c = train_test_split(\n",
    "    X_temp_c, y_temp_c, test_size=0.50, random_state=RANDOM_STATE, stratify=y_temp_c\n",
    ")\n",
    "\n",
    "print(\"Breast Cancer Split:\")\n",
    "print(f\"  Training:   {X_train_c.shape[0]} samples ({X_train_c.shape[0]/len(X_cancer)*100:.1f}%)\")\n",
    "print(f\"  Validation: {X_val_c.shape[0]} samples ({X_val_c.shape[0]/len(X_cancer)*100:.1f}%)\")\n",
    "print(f\"  Test:       {X_test_c.shape[0]} samples ({X_test_c.shape[0]/len(X_cancer)*100:.1f}%)\")\n",
    "print(f\"  Total:      {len(X_cancer)} samples\\n\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"Class distribution (stratification check):\")\n",
    "print(f\"  Original:   {y_cancer.value_counts(normalize=True).sort_index().values}\")\n",
    "print(f\"  Training:   {y_train_c.value_counts(normalize=True).sort_index().values}\")\n",
    "print(f\"  Validation: {y_val_c.value_counts(normalize=True).sort_index().values}\")\n",
    "print(f\"  Test:       {y_test_c.value_counts(normalize=True).sort_index().values}\")\n",
    "print(\"âœ“ Class proportions maintained across splits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing <a id='preprocessing'></a>\n",
    "\n",
    "### Why Scaling Matters\n",
    "\n",
    "**Linear and Logistic Regression** are sensitive to feature scales because:\n",
    "- Gradient descent converges faster with scaled features\n",
    "- Regularization (L1/L2) penalizes all features equally when scaled\n",
    "- Coefficients become directly comparable\n",
    "\n",
    "**Decision Trees** don't require scaling (they make splits based on thresholds, not distances).\n",
    "\n",
    "**Critical:** We fit the scaler on training data only and transform all sets to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale California Housing features\n",
    "scaler_housing = StandardScaler()\n",
    "\n",
    "# Fit on training data only!\n",
    "X_train_h_scaled = scaler_housing.fit_transform(X_train_h)\n",
    "X_val_h_scaled = scaler_housing.transform(X_val_h)\n",
    "X_test_h_scaled = scaler_housing.transform(X_test_h)\n",
    "\n",
    "print(\"California Housing - Feature Scaling:\")\n",
    "print(f\"  Original mean (train): {X_train_h.mean().mean():.3f}\")\n",
    "print(f\"  Original std (train):  {X_train_h.std().mean():.3f}\")\n",
    "print(f\"  Scaled mean (train):   {X_train_h_scaled.mean():.6f}\")\n",
    "print(f\"  Scaled std (train):    {X_train_h_scaled.std():.3f}\")\n",
    "print(\"âœ“ Features standardized (meanâ‰ˆ0, stdâ‰ˆ1)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Breast Cancer features\n",
    "scaler_cancer = StandardScaler()\n",
    "\n",
    "# Fit on training data only!\n",
    "X_train_c_scaled = scaler_cancer.fit_transform(X_train_c)\n",
    "X_val_c_scaled = scaler_cancer.transform(X_val_c)\n",
    "X_test_c_scaled = scaler_cancer.transform(X_test_c)\n",
    "\n",
    "print(\"Breast Cancer - Feature Scaling:\")\n",
    "print(f\"  Original mean (train): {X_train_c.mean().mean():.3f}\")\n",
    "print(f\"  Original std (train):  {X_train_c.std().mean():.3f}\")\n",
    "print(f\"  Scaled mean (train):   {X_train_c_scaled.mean():.6f}\")\n",
    "print(f\"  Scaled std (train):    {X_train_c_scaled.std():.3f}\")\n",
    "print(\"âœ“ Features standardized (meanâ‰ˆ0, stdâ‰ˆ1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline Models <a id='baseline'></a>\n",
    "\n",
    "### Why Baselines Matter\n",
    "\n",
    "Baselines provide context for model performance:\n",
    "- **Regression baseline:** Predicts the mean of training targets\n",
    "- **Classification baseline:** Predicts the majority class\n",
    "\n",
    "Any model worse than the baseline is essentially useless!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression baseline: mean predictor\n",
    "baseline_reg = DummyRegressor(strategy='mean')\n",
    "baseline_reg.fit(X_train_h_scaled, y_train_h)\n",
    "y_pred_baseline_reg = baseline_reg.predict(X_val_h_scaled)\n",
    "\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_val_h, y_pred_baseline_reg))\n",
    "baseline_mae = mean_absolute_error(y_val_h, y_pred_baseline_reg)\n",
    "baseline_r2 = r2_score(y_val_h, y_pred_baseline_reg)\n",
    "\n",
    "print(\"Regression Baseline (Mean Predictor):\")\n",
    "print(f\"  RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"  MAE:  {baseline_mae:.4f}\")\n",
    "print(f\"  RÂ²:   {baseline_r2:.4f}\")\n",
    "print(f\"\\nInterpretation: Always predicting {y_train_h.mean():.2f} gives RÂ²={baseline_r2:.4f}\")\n",
    "print(\"Any useful model should significantly outperform this!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification baseline: majority class predictor\n",
    "baseline_clf = DummyClassifier(strategy='most_frequent')\n",
    "baseline_clf.fit(X_train_c_scaled, y_train_c)\n",
    "y_pred_baseline_clf = baseline_clf.predict(X_val_c_scaled)\n",
    "\n",
    "baseline_acc = accuracy_score(y_val_c, y_pred_baseline_clf)\n",
    "baseline_f1 = f1_score(y_val_c, y_pred_baseline_clf)\n",
    "\n",
    "print(\"Classification Baseline (Majority Class Predictor):\")\n",
    "print(f\"  Accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"  F1 Score: {baseline_f1:.4f}\")\n",
    "print(f\"\\nInterpretation: Always predicting class {y_train_c.mode()[0]} gives {baseline_acc:.2%} accuracy\")\n",
    "print(\"This is because the dataset is imbalanced (~63% benign)\")\n",
    "print(\"A good model should achieve much higher accuracy and F1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regression: California Housing <a id='regression'></a>\n",
    "\n",
    "We'll train and compare:\n",
    "1. **Linear Regression** (no regularization)\n",
    "2. **Ridge Regression** (L2 regularization)\n",
    "3. **Lasso Regression** (L1 regularization)\n",
    "4. **Decision Tree Regressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Train Initial Models"
   ]
  }
    ,
    {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Initialize models\n",
        "models_reg = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
        "    'Lasso Regression': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n",
        "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results_reg = {}\n",
        "\n",
        "for name, model in models_reg.items():\n",
        "    model.fit(X_train_h_scaled, y_train_h)\n",
        "    y_val_pred = model.predict(X_val_h_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val_h, y_val_pred))\n",
        "    mae = mean_absolute_error(y_val_h, y_val_pred)\n",
        "    r2 = r2_score(y_val_h, y_val_pred)\n",
        "    results_reg[name] = {'RMSE': rmse, 'MAE': mae, 'RÂ²': r2}\n",
        "\n",
        "# Display results\n",
        "results_df_reg = pd.DataFrame(results_reg).T\n",
        "results_df_reg = results_df_reg.sort_values(by='RÂ²', ascending=False)\n",
        "\n",
        "print(\"Regression Model Performance on Validation Set:\")\n",
        "display(results_df_reg)"
    ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### 7.2 Hyperparameter Tuning with GridSearchCV"
    ]
    }
  ]
}